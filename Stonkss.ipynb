{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "G4XY7Udmgwxq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_maBC_JhgnBq",
        "outputId": "246d81eb-1522-4c0f-8a71-0d46708ed23c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7066326530612245,\n",
              " '              precision    recall  f1-score   support\\n\\n           0       0.71      0.69      0.70       194\\n           1       0.70      0.72      0.71       198\\n\\n    accuracy                           0.71       392\\n   macro avg       0.71      0.71      0.71       392\\nweighted avg       0.71      0.71      0.71       392\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "stock_data = pd.read_csv('stock_data_trend_based.csv')\n",
        "X = stock_data.iloc[:, :-1].values\n",
        "y = stock_data.iloc[:, -1].values\n",
        "\n",
        "# Recalculate features\n",
        "stock_data['Daily_Return'] = (stock_data['Close'] - stock_data['Open']) / stock_data['Open']\n",
        "stock_data['Price_Change'] = stock_data['Close'] - stock_data['Open']\n",
        "stock_data['Volatility'] = stock_data['Close'].rolling(window=5).std()\n",
        "\n",
        "# Moving Averages\n",
        "stock_data['SMA_5'] = stock_data['Close'].rolling(window=5).mean()\n",
        "stock_data['SMA_10'] = stock_data['Close'].rolling(window=10).mean()\n",
        "\n",
        "# Relative Strength Index (RSI)\n",
        "delta = stock_data['Close'].diff()\n",
        "gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
        "loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
        "rs = gain / loss\n",
        "stock_data['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "# MACD\n",
        "stock_data['EMA_12'] = stock_data['Close'].ewm(span=12, adjust=False).mean()\n",
        "stock_data['EMA_26'] = stock_data['Close'].ewm(span=26, adjust=False).mean()\n",
        "stock_data['MACD'] = stock_data['EMA_12'] - stock_data['EMA_26']\n",
        "\n",
        "# Bollinger Bands\n",
        "stock_data['BB_Mid'] = stock_data['Close'].rolling(window=20).mean()\n",
        "stock_data['BB_Upper'] = stock_data['BB_Mid'] + (2 * stock_data['Close'].rolling(window=20).std())\n",
        "stock_data['BB_Lower'] = stock_data['BB_Mid'] - (2 * stock_data['Close'].rolling(window=20).std())\n",
        "\n",
        "# Drop NaN values\n",
        "stock_data.dropna(inplace=True)\n",
        "\n",
        "# Define final features\n",
        "updated_features = [\n",
        "    'Open', 'High', 'Low', 'Close', 'Volume',\n",
        "    'Daily_Return', 'Price_Change', 'Volatility',\n",
        "    'SMA_5', 'SMA_10', 'RSI', 'MACD', 'BB_Upper', 'BB_Lower', 'Signal'\n",
        "]\n",
        "\n",
        "updated_data = stock_data[updated_features]\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_updated = updated_data.drop(columns=['Signal'])\n",
        "y_updated = updated_data['Signal']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_updated, y_updated, test_size=0.2, random_state=42, stratify=y_updated)\n",
        "\n",
        "# Standardize the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train a Random Forest Classifier with Hyperparameter Tuning\n",
        "rf_params = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "rf_grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Best Random Forest Model\n",
        "best_rf = rf_grid.best_estimator_\n",
        "y_pred_rf = best_rf.predict(X_test_scaled)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "classification_rep_rf = classification_report(y_test, y_pred_rf)\n",
        "\n",
        "# Return results\n",
        "accuracy_rf, classification_rep_rf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_rf)"
      ],
      "metadata": {
        "id": "gviBYKEti0D1",
        "outputId": "7cdf641d-e0bc-4ba9-bc44-00ec9b2843e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7066326530612245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cf = confusion_matrix(y_test, y_pred_rf)\n",
        "cf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMUG4Bebh5Q8",
        "outputId": "55f3528e-b6ee-4184-9744-a7f4265c1d3c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[134,  60],\n",
              "       [ 55, 143]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}